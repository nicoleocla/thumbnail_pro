{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip -q\n",
    "!pip install matplotlib -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install q- datasets\n",
    "!pip install transformers -q -U\n",
    "!pip install -q bitsandbytes sentencepiece accelerate loralib\n",
    "!pip install -q -U git+https://github.com/huggingface/perft.git\n",
    "!pip install hf_transfer -q -U\n",
    "!pip install pickleshare -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"LLaVA\"):\n",
    "    !git clone https://github.com/haotian-liu/LLaVA.git\n",
    "else:\n",
    "    print(\"LLaVA directory already exists. Skipping clone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Define the path to the builder.py file\n",
    "file_path = 'LLaVA/llava/model/builder.py'\n",
    "\n",
    "#Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "#Regular expression to find the block between 'vision_tower = model.get....\n",
    "pattern_block = (\n",
    "    r'(vision_tower = model.get_vision_tower\\(\\)\\n)'\n",
    "    r'.*?' #non-greedy match for any characters\n",
    "    r'(image_processor = vision_tower.image_processor)'\n",
    ")\n",
    "\n",
    "replacement_block = (\n",
    "    r'\\1' # keep starting line unchaged\n",
    "    '     if not vision_tower.is_loader:\\n'\n",
    "    '       print(\\'vision_tower is not loaded so loading it now\\')\\n'\n",
    "    '       vision_tower.load_model(device_map=device_map)\\n'\n",
    "    '       vision_tower.to(deice=device, dtype=torch.bfloat16)\\n'\n",
    "    '     else:\\n'\n",
    "    '       pint(\\'vision_tower is loaded\\')\\n'\n",
    "    r'    \\2' #keep the ending line unchanged\n",
    ")\n",
    "\n",
    "#replace the specific block\n",
    "content = re.sub(pattern_block, replacement_block, content, flegs=re.DOTALL)\n",
    "\n",
    "#Write the modified content back to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(content)\n",
    "print('The script has been updated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file_path = 'LLaVA/llava/model/builder.py'\n",
    "\n",
    "#read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    concept = file.read()\n",
    "    \n",
    "#regular expression to find 'float16' not preceded by 'b'\n",
    "pattern = r'(?<!b)float16'\n",
    "\n",
    "#check if there are any matches\n",
    "if re.search(pattern, content):\n",
    "    #Replace 'float16' with 'bfloat16'\n",
    "    modified_content = re.sub(pattern, 'bfloat16', content)\n",
    "    \n",
    "    #Write the modified contnet back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(modified_content)\n",
    "    \n",
    "    print(\"All necessary instances of floats have been replaced with..\")\n",
    "else:\n",
    "    print('No replacement needed. All instances of float16 already have.. ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can take up to 5 mins\n",
    "!pip install -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull\n",
    "# !pip install -e . -q\n",
    "\n",
    "!pip install protobuf -q -U\n",
    "!pip install --upgrade Pillow -q\n",
    "!pip install -e \".[train]\" -q\n",
    "!pip install flash-attn --no-build-isolation -q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#load model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, get_peft_model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from PIL import Image\n",
    "import transformers\n",
    "from transformers import AutoProcessor, Trainer, TrainingArgument, BitsA\n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_path = 'liuhaotian/llava-v1.6-mistral-7b'\n",
    "#model_path = \"Trelis/llava-v1.6-mistral-7b-PATCHED\"\n",
    "\n",
    "model_name=get_model_name_from_path(model_path)\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_path,\n",
    "    model_base=None,\n",
    "    model_name=model_name,\n",
    "    cache_dir='',\n",
    "    use_flash_attn=True,  \n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.config)\n",
    "#print(tokenizer.pad_token_id)\n",
    "#print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#check dtype of all modules, focusing on those not torch.bfloat16\n",
    "print(\"Modules not torch.bfloat16:\")\n",
    "for name, module in model.named_modules():\n",
    "    if hasattr(module, 'parameters') and list(module.parameters()):\n",
    "        #check if any parameter of the module is not bfloat16\n",
    "        if any(param.dtype != torch.bfloat16 for para in module.parameters()):\n",
    "            print(f\"{name}: {next(module.parameters()).dtype}\")\n",
    "    else:\n",
    "        #Optionally, acknowledge module without parameters if needed\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxifare-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
